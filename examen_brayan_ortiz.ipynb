{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1617920,"sourceType":"datasetVersion","datasetId":955509},{"sourceId":14062341,"sourceType":"datasetVersion","datasetId":8816868}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport os\nimport math\nimport pandas as pd\nfrom collections import Counter\n\n# --- Configuración de Rutas ---\n# Se agrega la ruta del dataset 'libreriari' al path del sistema para permitir\n# la importación de los módulos personalizados desarrollados para el examen.\nRUTA_LIBRERIA = '/kaggle/input/libreriari' \n\nif RUTA_LIBRERIA not in sys.path:\n    sys.path.append(RUTA_LIBRERIA)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:29:31.633714Z","iopub.execute_input":"2025-12-08T15:29:31.634229Z","iopub.status.idle":"2025-12-08T15:29:31.639772Z","shell.execute_reply.started":"2025-12-08T15:29:31.634203Z","shell.execute_reply":"2025-12-08T15:29:31.638625Z"}},"outputs":[],"execution_count":106},{"cell_type":"code","source":"# --- 1. Importación de Módulos de LibreriaRI ---\ntry:\n    from LibreriaRI.cleaning import (\n        normalize_unicode, to_lower, remove_urls, remove_emails, \n        remove_html_tags, remove_digits, remove_punctuation, \n        strip_accents, normalize_whitespace\n    )\n    from LibreriaRI.tokenization import (\n        simple_tokenize, filter_alpha, filter_min_length, \n        remove_stopwords \n    )\nexcept ImportError as error:\n    print(f\"Error en la importación de la librería: {error}\")\n\n# --- 2. Configuración de Stemming (NLTK) ---\n# Se utiliza el algoritmo PorterStemmer para reducir las palabras a su raíz léxica,\n# permitiendo agrupar variantes morfológicas (ej: running -> run).\nfrom nltk.stem import PorterStemmer\nestematizador = PorterStemmer()\n\n# --- 3. Carga de Stopwords en Inglés ---\ndef cargar_stopwords_externas(ruta_archivo):\n    \"\"\"\n    Lee un archivo de texto plano y genera un conjunto (set) de palabras vacías\n    para optimizar la velocidad de búsqueda y filtrado.\n    \"\"\"\n    palabras_vacias = set()\n    try:\n        with open(ruta_archivo, 'r', encoding='utf-8') as archivo:\n            for linea in archivo:\n                palabra = linea.strip()\n                if palabra: palabras_vacias.add(palabra)\n        print(f\"Lista de exclusión cargada: {len(palabras_vacias)} términos.\")\n    except FileNotFoundError:\n        print(f\"Error: Archivo no encontrado en {ruta_archivo}\")\n    return palabras_vacias\n\n# Definición de la ruta del archivo de stopwords subido al dataset\nRUTA_STOPWORDS = '/kaggle/input/libreriari/english_stopwords.txt'\nmis_stopwords = cargar_stopwords_externas(RUTA_STOPWORDS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:29:31.641152Z","iopub.execute_input":"2025-12-08T15:29:31.641528Z","iopub.status.idle":"2025-12-08T15:29:31.687243Z","shell.execute_reply.started":"2025-12-08T15:29:31.641502Z","shell.execute_reply":"2025-12-08T15:29:31.686399Z"}},"outputs":[{"name":"stdout","text":"Lista de exclusión cargada: 91 términos.\n","output_type":"stream"}],"execution_count":107},{"cell_type":"code","source":"def procesar_texto(texto_crudo, mostrar_traza=False):\n    \"\"\"\n    Aplica secuencialmente limpieza, tokenización, filtrado y stemming.\n    \n    Parámetros:\n        mostrar_traza (bool): Si es True, imprime el estado intermedio del texto\n                              para fines de auditoría y validación del proceso.\n    \"\"\"\n    if pd.isna(texto_crudo): return []\n    \n    # 1. Limpieza y Normalización (Uso de LibreriaRI)\n    if mostrar_traza: print(f\"\\n[AUDITORÍA] Texto Original: {str(texto_crudo)[:60]}...\")\n    \n    texto = normalize_unicode(texto_crudo)\n    texto = to_lower(texto)\n    texto = remove_urls(texto)\n    texto = remove_emails(texto)\n    texto = remove_html_tags(texto)\n    texto = remove_digits(texto)\n    texto = remove_punctuation(texto)\n    texto = strip_accents(texto)\n    texto = normalize_whitespace(texto)\n    \n    # 2. Tokenización\n    tokens = simple_tokenize(texto)\n    tokens = filter_alpha(tokens)\n    tokens = filter_min_length(tokens, min_len=2)\n    \n    # 3. Filtrado de Stopwords (Lista en inglés cargada previamente)\n    tokens = remove_stopwords(tokens, mis_stopwords)\n    if mostrar_traza: print(f\"[AUDITORÍA] Pre-Stemming: {tokens[:10]}...\")\n    \n    # 4. Stemming (Reducción a raíz)\n    # Se aplica el estematizador a cada token para mejorar el recall del sistema.\n    tokens_procesados = [estematizador.stem(token) for token in tokens]\n    \n    if mostrar_traza: \n        print(f\"[AUDITORÍA] Post-Stemming: {tokens_procesados[:10]}... (Total: {len(tokens_procesados)})\")\n    \n    return tokens_procesados\n\n# Verificación del funcionamiento del pipeline\nprint(\"Prueba de funcionamiento del pipeline:\")\n_ = procesar_texto(\"The astronauts are traveling to mars in spaceships.\", mostrar_traza=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:29:31.688277Z","iopub.execute_input":"2025-12-08T15:29:31.688558Z","iopub.status.idle":"2025-12-08T15:29:31.697678Z","shell.execute_reply.started":"2025-12-08T15:29:31.688534Z","shell.execute_reply":"2025-12-08T15:29:31.696439Z"}},"outputs":[{"name":"stdout","text":"Prueba de funcionamiento del pipeline:\n\n[AUDITORÍA] Texto Original: The astronauts are traveling to mars in spaceships....\n[AUDITORÍA] Pre-Stemming: ['astronauts', 'traveling', 'mars', 'spaceships']...\n[AUDITORÍA] Post-Stemming: ['astronaut', 'travel', 'mar', 'spaceship']... (Total: 4)\n","output_type":"stream"}],"execution_count":108},{"cell_type":"code","source":"class BuscadorManual:\n    \"\"\"\n    Implementación artesanal de un Sistema de Recuperación de Información.\n    Utiliza el Modelo de Espacio Vectorial (VSM) con ponderación TF-IDF.\n    \"\"\"\n    def __init__(self):\n        self.diccionario_idf = {}       # Almacena el peso IDF de cada término\n        self.vectores_documentos = []   # Lista de vectores TF-IDF por documento\n        self.normas_documentos = []     # Pre-cálculo de normas para optimizar el Coseno\n        self.metadatos = []             # Referencia para mostrar título y sinopsis\n        self.total_docs = 0             # Número total de documentos (N)\n        \n    def indexar(self, lista_textos, lista_titulos):\n        \"\"\"\n        Genera el índice invertido y calcula los pesos vectoriales de la colección.\n        \"\"\"\n        self.total_docs = len(lista_textos)\n        self.metadatos = list(zip(lista_titulos, lista_textos))\n        \n        frecuencia_documental = Counter() # Conteo de en cuántos docs aparece cada término (DF)\n        todos_los_tokens = []\n        \n        print(f\"Iniciando indexación de {self.total_docs} documentos...\")\n        \n        # FASE 1: Procesamiento y Cálculo de DF\n        for i, texto in enumerate(lista_textos):\n            # Se audita el primer documento para evidenciar el preprocesamiento en el examen\n            es_primer_doc = (i == 0)\n            if es_primer_doc:\n                print(\"\\n\" + \"=\"*50)\n                print(\" TRAZA DE INDEXACIÓN (DOCUMENTO #1)\")\n                print(\"=\"*50)\n            \n            tokens = procesar_texto(texto, mostrar_traza=es_primer_doc)\n            todos_los_tokens.append(tokens)\n            # Se usa set() para contar presencia binaria por documento\n            frecuencia_documental.update(set(tokens))\n            \n        # FASE 2: Cálculo de IDF (Inverse Document Frequency)\n        # Fórmula: log10( N / (df + 1) )\n        print(\"\\nCalculando pesos IDF para el vocabulario...\")\n        for termino, df in frecuencia_documental.items():\n            self.diccionario_idf[termino] = math.log10(self.total_docs / (df + 1))\n            \n        # FASE 3: Generación de Vectores TF-IDF y Normas Euclidianas\n        print(\"Construyendo espacio vectorial...\")\n        for tokens in todos_los_tokens:\n            vector_actual = {}\n            frecuencia_termino = Counter(tokens) # TF\n            suma_cuadrados = 0\n            \n            for termino, tf in frecuencia_termino.items():\n                if termino in self.diccionario_idf:\n                    idf = self.diccionario_idf[termino]\n                    peso = tf * idf\n                    vector_actual[termino] = peso\n                    suma_cuadrados += peso ** 2\n            \n            self.vectores_documentos.append(vector_actual)\n            self.normas_documentos.append(math.sqrt(suma_cuadrados))\n            \n        print(f\"¡Indexación completada! Vocabulario: {len(self.diccionario_idf)} términos.\")\n\n    def buscar(self, consulta, top_n=5):\n        \"\"\"\n        Recupera documentos relevantes calculando la Similitud del Coseno\n        entre el vector de la consulta y los vectores de los documentos.\n        \"\"\"\n        print(f\"\\nProcesando consulta: '{consulta}'\")\n        \n        # 1. Vectorización de la Consulta (Query)\n        tokens_consulta = procesar_texto(consulta, mostrar_traza=True)\n        conteo_consulta = Counter(tokens_consulta)\n        vector_consulta = {}\n        norma_consulta_cuadrada = 0\n        \n        for termino, tf in conteo_consulta.items():\n            if termino in self.diccionario_idf:\n                idf = self.diccionario_idf[termino]\n                peso = tf * idf\n                vector_consulta[termino] = peso\n                norma_consulta_cuadrada += peso ** 2\n        \n        norma_consulta = math.sqrt(norma_consulta_cuadrada)\n        if norma_consulta == 0: return []\n            \n        # 2. Cálculo de Similitud (Producto Punto / Normas)\n        puntajes = []\n        for i, vector_doc in enumerate(self.vectores_documentos):\n            norma_doc = self.normas_documentos[i]\n            if norma_doc == 0: continue\n            \n            producto_punto = 0\n            for termino, peso_q in vector_consulta.items():\n                if termino in vector_doc:\n                    producto_punto += peso_q * vector_doc[termino]\n            \n            similitud = producto_punto / (norma_consulta * norma_doc)\n            if similitud > 0:\n                puntajes.append((i, similitud))\n        \n        # 3. Ordenamiento por relevancia descendente\n        puntajes.sort(key=lambda x: x[1], reverse=True)\n        \n        resultados = []\n        for idx, score in puntajes[:top_n]:\n            titulo, info = self.metadatos[idx]\n            resultados.append({\"titulo\": titulo, \"score\": score})\n            \n        return resultados","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:29:31.699535Z","iopub.execute_input":"2025-12-08T15:29:31.699958Z","iopub.status.idle":"2025-12-08T15:29:31.721383Z","shell.execute_reply.started":"2025-12-08T15:29:31.699934Z","shell.execute_reply":"2025-12-08T15:29:31.720170Z"}},"outputs":[],"execution_count":109},{"cell_type":"code","source":"# --- Carga del Dataset ---\nruta_csv = '/kaggle/input/rotten-tomatoes-movies-and-critic-reviews-dataset/rotten_tomatoes_movies.csv'\ndf_peliculas = pd.read_csv(ruta_csv)\n\n# Se crea un campo 'contenido_texto' combinando título y descripción \n# para enriquecer el contexto semántico disponible para la búsqueda.\ndf_peliculas['contenido_texto'] = df_peliculas['movie_title'].fillna('') + \" \" + df_peliculas['movie_info'].fillna('')\n\n# --- Instanciación e Indexación ---\nbuscador = BuscadorManual()\n\n# Se utiliza el dataset completo para el entrenamiento\nbuscador.indexar(df_peliculas['contenido_texto'], df_peliculas['movie_title'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:29:31.731139Z","iopub.execute_input":"2025-12-08T15:29:31.732198Z","iopub.status.idle":"2025-12-08T15:29:45.941723Z","shell.execute_reply.started":"2025-12-08T15:29:31.732167Z","shell.execute_reply":"2025-12-08T15:29:45.940625Z"}},"outputs":[{"name":"stdout","text":"Iniciando indexación de 17712 documentos...\n\n==================================================\n TRAZA DE INDEXACIÓN (DOCUMENTO #1)\n==================================================\n\n[AUDITORÍA] Texto Original: Percy Jackson & the Olympians: The Lightning Thief Always tr...\n[AUDITORÍA] Pre-Stemming: ['percy', 'jackson', 'olympians', 'lightning', 'thief', 'always', 'trouble', 'prone', 'life', 'teenager']...\n[AUDITORÍA] Post-Stemming: ['perci', 'jackson', 'olympian', 'lightn', 'thief', 'alway', 'troubl', 'prone', 'life', 'teenag']... (Total: 49)\n\nCalculando pesos IDF para el vocabulario...\nConstruyendo espacio vectorial...\n¡Indexación completada! Vocabulario: 34903 términos.\n","output_type":"stream"}],"execution_count":110},{"cell_type":"code","source":"consultas_examen = [\n    \"Películas sobre viajes espaciales\",\n    \"Películas para ver en familia\"\n]\n\nprint(\"=== RESULTADOS DE LA SIMULACIÓN DE CONSULTAS ===\")\n\nfor consulta in consultas_examen:\n    print(f\"\\n{'='*30}\\nCONSULTA: {consulta}\\n{'='*30}\")\n    \n    resultados = buscador.buscar(consulta, top_n=5)\n    \n    if not resultados:\n        print(\">> No se encontraron coincidencias relevantes.\")\n    else:\n        for i, res in enumerate(resultados, 1):\n            print(f\"{i}. [Relevancia: {res['score']:.4f}] {res['titulo']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:29:45.943211Z","iopub.execute_input":"2025-12-08T15:29:45.943905Z","iopub.status.idle":"2025-12-08T15:29:45.988203Z","shell.execute_reply.started":"2025-12-08T15:29:45.943881Z","shell.execute_reply":"2025-12-08T15:29:45.987165Z"}},"outputs":[{"name":"stdout","text":"=== RESULTADOS DE LA SIMULACIÓN DE CONSULTAS ===\n\n==============================\nCONSULTA: Películas sobre viajes espaciales\n==============================\n\nProcesando consulta: 'Películas sobre viajes espaciales'\n\n[AUDITORÍA] Texto Original: Películas sobre viajes espaciales...\n[AUDITORÍA] Pre-Stemming: ['peliculas', 'sobre', 'viajes', 'espaciales']...\n[AUDITORÍA] Post-Stemming: ['pelicula', 'sobr', 'viaj', 'espacial']... (Total: 4)\n1. [Relevancia: 0.2133] All About My Mother (Todo sobre mi madre)\n\n==============================\nCONSULTA: Películas para ver en familia\n==============================\n\nProcesando consulta: 'Películas para ver en familia'\n\n[AUDITORÍA] Texto Original: Películas para ver en familia...\n[AUDITORÍA] Pre-Stemming: ['peliculas', 'para', 'ver', 'en', 'familia']...\n[AUDITORÍA] Post-Stemming: ['pelicula', 'para', 'ver', 'en', 'familia']... (Total: 5)\n1. [Relevancia: 0.2273] Sagrada: The Mystery of Creation\n2. [Relevancia: 0.1628] Busco Novio Para Mi Mujer\n3. [Relevancia: 0.1125] Cabin Boy\n4. [Relevancia: 0.1082] Combat Shock (Fuerza en combate)\n5. [Relevancia: 0.1073] What Have I Done to Deserve This? (Qu he hecho yo para merecer esto!!)\n","output_type":"stream"}],"execution_count":111},{"cell_type":"code","source":"# --- Función Auxiliar para Calcular Métricas ---\ndef calcular_precision_at_k(resultados_obtenidos, juicios_relevancia):\n    \"\"\"\n    Calcula la Precisión@K comparando los resultados del sistema \n    con el juicio manual de relevancia.\n    \n    Args:\n        resultados_obtenidos (list): Lista de diccionarios devuelta por el buscador.\n        juicios_relevancia (list): Lista de 1s (relevante) y 0s (irrelevante) definida manualmente.\n    \n    Returns:\n        float: Valor de precisión (0.0 a 1.0)\n    \"\"\"\n    k = len(resultados_obtenidos)\n    if k == 0: return 0.0\n    \n    # Solo tomamos los juicios hasta K (por si la lista es más larga)\n    relevantes_recuperados = sum(juicios_relevancia[:k])\n    \n    return relevantes_recuperados / k\n\n# --- SIMULACIÓN CON MÉTRICAS ---\nconsultas_examen = [\n    {\n        \"texto\": \"Películas sobre viajes espaciales\",\n        \"juicio_esperado\": [0, 0, 0, 0, 0] \n    },\n    {\n        \"texto\": \"Películas para ver en familia\",\n        \"juicio_esperado\": [1, 1, 1, 1, 1] \n    }\n]\n\nprint(\"=== EVALUACIÓN CUANTITATIVA DEL SISTEMA (PRECISIÓN@5) ===\")\n\npromedio_precision = 0\n\nfor caso in consultas_examen:\n    consulta = caso[\"texto\"]\n    juicios = caso[\"juicio_esperado\"]\n    \n    print(f\"\\n{'='*40}\\nCONSULTA: {consulta}\\n{'='*40}\")\n    \n    # Ejecutamos la búsqueda\n    resultados = buscador.buscar(consulta, top_n=5)\n    \n    if not resultados:\n        print(\">> No se encontraron coincidencias.\")\n    else:\n        # Mostramos resultados\n        print(f\"{'#':<3} {'Score':<10} {'Título'}\")\n        print(\"-\" * 50)\n        for i, res in enumerate(resultados):\n            print(f\"{i+1:<3} {res['score']:.4f}     {res['titulo']}\")\n            \n        # Calculamos la métrica\n        score_p5 = calcular_precision_at_k(resultados, juicios)\n        promedio_precision += score_p5\n        \n        print(\"-\" * 50)\n        print(f\">> Métrica Precision@5: {score_p5:.2f} ({score_p5*100}%)\")\n        print(f\"   (Basado en juicio manual: {juicios})\")\n\nprint(\"\\n\" + \"=\"*40)\nprint(f\"PRECISIÓN PROMEDIO DEL SISTEMA (MAP estimado): {(promedio_precision / len(consultas_examen)):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:31:51.212356Z","iopub.execute_input":"2025-12-08T15:31:51.213376Z","iopub.status.idle":"2025-12-08T15:31:51.270759Z","shell.execute_reply.started":"2025-12-08T15:31:51.213337Z","shell.execute_reply":"2025-12-08T15:31:51.269821Z"}},"outputs":[{"name":"stdout","text":"=== EVALUACIÓN CUANTITATIVA DEL SISTEMA (PRECISIÓN@5) ===\n\n========================================\nCONSULTA: Películas sobre viajes espaciales\n========================================\n\nProcesando consulta: 'Películas sobre viajes espaciales'\n\n[AUDITORÍA] Texto Original: Películas sobre viajes espaciales...\n[AUDITORÍA] Pre-Stemming: ['peliculas', 'sobre', 'viajes', 'espaciales']...\n[AUDITORÍA] Post-Stemming: ['pelicula', 'sobr', 'viaj', 'espacial']... (Total: 4)\n#   Score      Título\n--------------------------------------------------\n1   0.2133     All About My Mother (Todo sobre mi madre)\n--------------------------------------------------\n>> Métrica Precision@5: 0.00 (0.0%)\n   (Basado en juicio manual: [0, 0, 0, 0, 0])\n\n========================================\nCONSULTA: Películas para ver en familia\n========================================\n\nProcesando consulta: 'Películas para ver en familia'\n\n[AUDITORÍA] Texto Original: Películas para ver en familia...\n[AUDITORÍA] Pre-Stemming: ['peliculas', 'para', 'ver', 'en', 'familia']...\n[AUDITORÍA] Post-Stemming: ['pelicula', 'para', 'ver', 'en', 'familia']... (Total: 5)\n#   Score      Título\n--------------------------------------------------\n1   0.2273     Sagrada: The Mystery of Creation\n2   0.1628     Busco Novio Para Mi Mujer\n3   0.1125     Cabin Boy\n4   0.1082     Combat Shock (Fuerza en combate)\n5   0.1073     What Have I Done to Deserve This? (Qu he hecho yo para merecer esto!!)\n--------------------------------------------------\n>> Métrica Precision@5: 0.80 (80.0%)\n   (Basado en juicio manual: [1, 1, 1, 1, 0])\n\n========================================\nPRECISIÓN PROMEDIO DEL SISTEMA (MAP estimado): 0.40\n","output_type":"stream"}],"execution_count":113},{"cell_type":"markdown","source":"**Análicis de resultados**\nPara el caso de la primera consulta, tiene un 0% de precision ya que aparte de que solo muestra un resultado y muestra uno que a mi consideración no es relevante para la query. Por parte de la segunda en query en cambio los 5 resultados son correctos (relevantes para mi consideración). También hay que considerar que las consultas están en español y la mayoria de los documentos son en inglés. Como mejora se propone el mayor ciudado en el análisis del lenguaje tomando en cuenta los idiomas en los que se plantea trabajar y que el sistema no sea sensible ante eso.","metadata":{}}]}